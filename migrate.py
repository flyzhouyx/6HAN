import pandas as pd
import json
import ipaddress
from typing import Dict, List, Optional, Tuple

# é…ç½®é¡¹
SIMILARITY_PATH = "Data/similarity_retrieval_result.csv"  # ç›¸ä¼¼æ£€ç´¢ç»“æœ
SEED_PATTERN_PATH = "Data/ipv6_patterns_result.json"    # ç§å­æ¨¡å¼åº“
OUTPUT_PATH = "Data/non_seed_patterns_result.json"      # éç§å­æ¨¡å¼è¾“å‡ºè·¯å¾„

# è¿ç§»å‚æ•°
MAX_RETRY_RANK = 5  # æœ€å¤§é™çº§åŒ¹é…rankï¼ˆè‹¥rank=1æ— æ¨¡å¼ï¼Œæœ€å¤šæ£€æŸ¥åˆ°rank=5ï¼‰
EXAMPLE_COUNT = 3   # æ¯ä¸ªæ¨¡å¼ç”Ÿæˆçš„ç¤ºä¾‹åœ°å€æ•°é‡

def get_prefix_fixed_part(ipv6_prefix: str) -> Tuple[str, int]:
    """è§£æIPv6å‰ç¼€ï¼Œè¿”å›32ä½å›ºå®šéƒ¨åˆ†å­—ç¬¦ä¸²å’Œå›ºå®šä½æ•°L"""
    try:
        prefix_str, len_str = ipv6_prefix.split("/")
        prefix_len = int(len_str)
        full_ip = ipaddress.IPv6Address(prefix_str).exploded
        full_ip_no_colon = full_ip.replace(":", "")
        fixed_len = prefix_len // 4
        fixed_part = full_ip_no_colon[:fixed_len]
        return fixed_part, fixed_len
    except Exception as e:
        print(f"âš ï¸ è§£æå‰ç¼€[{ipv6_prefix}]å¤±è´¥ï¼š{e}ï¼Œè·³è¿‡è¯¥å‰ç¼€")
        return "", 0


def match_seed_pattern(non_seed_prefix: str, similarity_df: pd.DataFrame,
                       seed_patterns: Dict[str, List[Dict]]) -> Optional[Tuple[str, List[Dict], str]]:
    """
    ä¸ºéç§å­å‰ç¼€åŒ¹é…ç§å­æ¨¡å¼ï¼Œæ–°å¢è¿”å›migration_suggestion
    è¿”å›ï¼š(åŒ¹é…çš„ç§å­å‰ç¼€, ç§å­æ¨¡å¼åˆ—è¡¨, migration_suggestion)ï¼Œæ— åŒ¹é…åˆ™è¿”å›None
    """
    non_seed_similar = similarity_df[similarity_df["non_seed_prefix"] == non_seed_prefix].sort_values("rank")

    for _, row in non_seed_similar.iterrows():
        seed_prefix = row["similar_seed_prefix"]
        seed_rank = row["rank"]
        # æå–å½“å‰è¡Œçš„migration_suggestion
        migration_suggestion = row.get("migration_suggestion", "")

        if seed_prefix in seed_patterns and len(seed_patterns[seed_prefix]) > 0:
            print(
                f"âœ… éç§å­[{non_seed_prefix}]åŒ¹é…åˆ°ç§å­[{seed_prefix}]ï¼ˆrank={seed_rank}ï¼‰ï¼Œå…±{len(seed_patterns[seed_prefix])}ä¸ªæ¨¡å¼")
            return seed_prefix, seed_patterns[seed_prefix], migration_suggestion

        if seed_rank >= MAX_RETRY_RANK:
            break

    print(f"âš ï¸ éç§å­[{non_seed_prefix}]æœªåŒ¹é…åˆ°æœ‰æ•ˆç§å­æ¨¡å¼ï¼ˆå·²å°è¯•å‰{MAX_RETRY_RANK}ä¸ªrankï¼‰")
    return None, None, None


def migrate_pattern(non_seed_prefix: str, seed_patterns: List[Dict], fixed_part: str, fixed_len: int) -> List[Dict]:
    """å°†ç§å­æ¨¡å¼è¿ç§»åˆ°éç§å­å‰ç¼€ï¼šæ›¿æ¢å›ºå®šéƒ¨åˆ†ï¼Œç”Ÿæˆç¤ºä¾‹åœ°å€"""
    non_seed_patterns = []

    for seed_pattern_info in seed_patterns:
        seed_pattern = seed_pattern_info["pattern"]
        seed_count = seed_pattern_info["count"]

        if len(seed_pattern) != 32:
            print(f"âš ï¸ ç§å­æ¨¡å¼[{seed_pattern}]é•¿åº¦å¼‚å¸¸ï¼ˆé32ä½ï¼‰ï¼Œè·³è¿‡")
            continue

        migrated_pattern = fixed_part + seed_pattern[fixed_len:]

        example_addresses = []
        for i in range(EXAMPLE_COUNT):
            replace_val = ["1", "2", "d"][i % EXAMPLE_COUNT]
            addr_no_colon = migrated_pattern.replace("*", replace_val)
            if len(addr_no_colon) < 32:
                addr_no_colon = addr_no_colon.ljust(32, "0")
            try:
                addr_segments = [addr_no_colon[i * 4:(i + 1) * 4] for i in range(8)]
                addr_with_colon = ":".join(addr_segments)
                standard_addr = ipaddress.IPv6Address(addr_with_colon).compressed
                example_addresses.append(standard_addr)
            except Exception as e:
                print(f"âš ï¸ ç”Ÿæˆç¤ºä¾‹åœ°å€å¤±è´¥ï¼ˆæ¨¡å¼ï¼š{migrated_pattern}ï¼‰ï¼š{e}")
                example_addresses.append(f"invalid_addr_{i + 1}")

        non_seed_patterns.append({
            "pattern": migrated_pattern,
            "addresses": example_addresses,
            "count": seed_count,
            "source_seed_pattern": seed_pattern
        })

    return non_seed_patterns


def load_input_data() -> Tuple[pd.DataFrame, Dict[str, List[Dict]]]:
    """è¯»å–ç›¸ä¼¼æ£€ç´¢ç»“æœå’Œç§å­æ¨¡å¼åº“ï¼Œç¡®ä¿åŒ…å«migration_suggestionåˆ—"""
    similarity_df = pd.read_csv(SIMILARITY_PATH).drop_duplicates(subset=["non_seed_prefix", "rank"])
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨migration_suggestionåˆ—
    if "migration_suggestion" not in similarity_df.columns:
        raise ValueError("similarity_retrieval_result.csvä¸­æœªæ‰¾åˆ°migration_suggestionåˆ—")
    print(f"âœ… åŠ è½½ç›¸ä¼¼æ£€ç´¢ç»“æœï¼šå…±{len(similarity_df)}æ¡è®°å½•ï¼Œ{similarity_df['non_seed_prefix'].nunique()}ä¸ªéç§å­å‰ç¼€")

    with open(SEED_PATTERN_PATH, "r", encoding="utf-8") as f:
        seed_patterns = json.load(f)
    print(
        f"âœ… åŠ è½½ç§å­æ¨¡å¼åº“ï¼šå…±{len(seed_patterns)}ä¸ªç§å­å‰ç¼€ï¼Œ{sum(len(pats) for pats in seed_patterns.values())}ä¸ªæ¨¡å¼")

    return similarity_df, seed_patterns


def batch_migrate_patterns() -> Dict[str, Dict]:
    """æ‰¹é‡ä¸ºæ‰€æœ‰éç§å­å‰ç¼€æ‰§è¡Œæ¨¡å¼è¿ç§»ï¼Œæ–°å¢æ”¶é›†migration_suggestion"""
    similarity_df, seed_patterns = load_input_data()
    non_seed_result = {}

    unique_non_seeds = similarity_df["non_seed_prefix"].unique()
    for non_seed in unique_non_seeds:
        print(f"\n=== å¤„ç†éç§å­å‰ç¼€ï¼š{non_seed} ===")

        fixed_part, fixed_len = get_prefix_fixed_part(non_seed)
        if not fixed_part or fixed_len == 0:
            continue

        # è·å–åŒ¹é…çš„ç§å­æ¨¡å¼åŠå¯¹åº”çš„migration_suggestion
        matched_seed, matched_patterns, migration_suggestion = match_seed_pattern(non_seed, similarity_df, seed_patterns)
        if not matched_seed or not matched_patterns:
            continue

        migrated_patterns = migrate_pattern(non_seed, matched_patterns, fixed_part, fixed_len)
        if not migrated_patterns:
            print(f"âš ï¸ éç§å­[{non_seed}]æœªç”Ÿæˆæœ‰æ•ˆæ¨¡å¼")
            continue

        # ç»“æœä¸­æ·»åŠ migration_suggestion
        non_seed_result[non_seed] = {
            "migrated_patterns": migrated_patterns,
            "source_seed_prefix": matched_seed,
            "prefix_fixed_part": fixed_part,
            "prefix_fixed_length": fixed_len,
            "migration_suggestion": migration_suggestion  # æ–°å¢å­—æ®µ
        }

    print(f"\nâœ… æ¨¡å¼è¿ç§»å®Œæˆï¼š{len(non_seed_result)}ä¸ªéç§å­å‰ç¼€ç”Ÿæˆæœ‰æ•ˆæ¨¡å¼")
    return non_seed_result


def save_migrated_patterns(non_seed_result: Dict[str, Dict]):
    """ä¿å­˜éç§å­æ¨¡å¼ç»“æœåˆ°JSONæ–‡ä»¶ï¼ŒåŒ…å«migration_suggestion"""
    output_data = {}
    for non_seed, info in non_seed_result.items():
        patterns = [
            {k: v for k, v in pat.items() if k != "source_seed_pattern"}
            for pat in info["migrated_patterns"]
        ]
        output_data[non_seed] = {
            "patterns": patterns,
            "metadata": {
                "source_seed_prefix": info["source_seed_prefix"],
                "prefix_fixed_part": info["prefix_fixed_part"],
                "prefix_fixed_length": info["prefix_fixed_length"],
                "migration_suggestion": info["migration_suggestion"]  # å†™å…¥ç»“æœæ–‡ä»¶
            }
        }

    with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    print(f"âœ… éç§å­æ¨¡å¼ç»“æœå·²ä¿å­˜è‡³ï¼š{OUTPUT_PATH}")
    print(
        f"ğŸ“Š ç»“æœç»Ÿè®¡ï¼šå…±{len(output_data)}ä¸ªéç§å­å‰ç¼€ï¼Œ{sum(len(info['patterns']) for info in output_data.values())}ä¸ªæ¨¡å¼")

if __name__ == "__main__":
    non_seed_pattern_result = batch_migrate_patterns()
    if non_seed_pattern_result:
        save_migrated_patterns(non_seed_pattern_result)
    else:
        print("âŒ æœªç”Ÿæˆä»»ä½•éç§å­æ¨¡å¼ï¼Œæ— éœ€ä¿å­˜")